{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import chaospy as cp\n",
    "import monte_carlo as mc\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vewk3_models import *\n",
    "#from scipy_vewk3 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Taken from Segers et al Hypertension 2000\n",
    "closed_loop_base_pars = {'C_ao': 1.13, \n",
    "             'E_max': 1.5, \n",
    "             'E_min': 0.03,\n",
    "             'R_mv': 0.006,\n",
    "             'R_sys': 1.11,\n",
    "             'T': 0.85,\n",
    "             'Z_ao': 0.033,\n",
    "             't_peak': 0.3,\n",
    "             'C_sv': 11,\n",
    "             'V_tot': 300\n",
    "            }\n",
    "\n",
    "\n",
    "ve_closed = VaryingElastance()\n",
    "ve_closed.set_pars(**closed_loop_base_pars)\n",
    "var_dict, t_eval, scipy_sol = solve_to_steady_state(ve_closed, n_cycles=15)\n",
    "ret_dict = calc_summary(var_dict)\n",
    "print(ret_dict)\n",
    "plot_pressures(var_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample to compare with Stergiopolus 1999 Open Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One factor at a time analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def ofat(ve_model, params, dev, sigma_x):\n",
    "    ve_model.set_pars(**params)\n",
    "    var_dict, t_eval, scipy_sol = solve_to_steady_state(ve_model)\n",
    "    ret_dict = calc_summary(var_dict)\n",
    "    df0 = pd.DataFrame(ret_dict, index=[0], )\n",
    "    input_names = sorted(params.keys())\n",
    "    data_array = []\n",
    "    dydx = pd.DataFrame()\n",
    "    pct_sensitivities = pd.DataFrame()\n",
    "    sigma_normalized_sens = pd.DataFrame()\n",
    "    total_variance = 0*df0\n",
    "    for par in input_names:\n",
    "        pars = dict(params)\n",
    "        pars[par] = (1+dev)*pars[par]\n",
    "        ve_model.set_pars(**pars)\n",
    "        var_dict, t_eval, scipy_sol = solve_to_steady_state(ve_model)\n",
    "        ret_dict = calc_summary(var_dict)\n",
    "        #dydx.loc[par][df0.columns] = (pd.DataFrame(ret_dict, index=[par,]) - df0.loc[0]) #/(dev*params[par])\n",
    "        dydx = dydx.append( (pd.DataFrame(ret_dict, index=[par,]) - df0.loc[0])/(dev*params[par]))\n",
    "        \n",
    "        partial_variance = (dydx.loc[par]*sigma_x.loc[0,par])**2\n",
    "        total_variance = total_variance + partial_variance\n",
    "        partial_variance.name = par\n",
    "        sigma_normalized_sens =  sigma_normalized_sens.append(partial_variance)\n",
    "        \n",
    "        pct_sens  = 100*dydx.loc[par]*(params[par]/df0.loc[0])\n",
    "        pct_sens.name = par\n",
    "        pct_sensitivities = pct_sensitivities.append(pct_sens)\n",
    "        data_array.append(ret_dict)\n",
    "    df = pd.DataFrame(data_array, index=input_names)\n",
    "    sigma_normalized_sens = sigma_normalized_sens/total_variance.loc[0]\n",
    "    return dydx, pct_sensitivities, sigma_normalized_sens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_loop_sa_pars = {'C_ao': 1.13, \n",
    "             'E_max': 1.5, \n",
    "             'E_min': 0.03,\n",
    "             'C_sv': 10,\n",
    "             'R_sys': 1.11,\n",
    "             'T': 0.85,\n",
    "             'Z_ao': 0.033,\n",
    "             'V_tot':300\n",
    "            }\n",
    "\n",
    "dev = 0.1\n",
    "ve_closed = VaryingElastance()\n",
    "ve_closed.set_pars(**closed_loop_base_pars)\n",
    "finite_difference_step = np.sqrt(1e-7) #1e-3 # sqrt(accuracy of ode)\n",
    "sigma_x = np.sqrt(pd.DataFrame(closed_loop_sa_pars, index=[0,])**2 * dev / 6)\n",
    "res = ofat(ve_closed, closed_loop_sa_pars, finite_difference_step, sigma_x)\n",
    "closed_loop_ofat_results = dict(dydx=res[0], pct_sens=res[1], sigma_sens=res[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global 10% uncertainty analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Closed loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_loop_sa_pars = {'C_ao': 1.13, \n",
    "             'E_max': 1.5, \n",
    "             'E_min': 0.03,\n",
    "             'C_sv': 10,\n",
    "             'R_sys': 1.11,\n",
    "             'T': 0.85,\n",
    "             'Z_ao': 0.033,\n",
    "             #'V_tot':300,\n",
    "             't_peak':0.3,\n",
    "             'R_mv':0.006\n",
    "            }\n",
    "\n",
    "dev = 0.1\n",
    "input_names = sorted(closed_loop_sa_pars.keys())\n",
    "\n",
    "dists = []\n",
    "for par in input_names:\n",
    "    par_nominal = closed_loop_sa_pars[par]\n",
    "    par_range = np.array([1-dev, 1+dev])*par_nominal\n",
    "    dists.append(cp.Uniform(*par_range))\n",
    "\n",
    "joint_dist = cp.J(*dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorized_rapper_for_uqsa(samples):\n",
    "    results = []\n",
    "    for sample in samples:\n",
    "        sample_pars = dict(closed_loop_base_pars)\n",
    "        for idx, par in enumerate(input_names):\n",
    "            sample_pars[par] = sample[idx]\n",
    "        ve_closed = VaryingElastance()\n",
    "        ve_closed.set_pars(**sample_pars)\n",
    "        var_dict, t_eval, scipy_sol = solve_to_steady_state(ve_closed)\n",
    "        #results.append(var_dict)\n",
    "        ret_dict = calc_summary(var_dict)\n",
    "        results.append(ret_dict)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ns=5000\n",
    "A, B, C = mc.generate_sample_matrices(Ns, joint_dist)\n",
    "dataA, dataB, dataC = mc.evaluate_samples(vectorized_rapper_for_uqsa, A, B, eval_mode=\"parallel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfA = pd.DataFrame(dataA)\n",
    "dfB = pd.DataFrame(dataB)\n",
    "#dfsC = [pd.DataFrame(data) for data in dataC] # doesn't work\n",
    "dfsC = [pd.DataFrame(list(data)) for data in dataC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfA[\"PP\"] = dfA[\"P_sys\"] - dfA[\"P_dia\"]\n",
    "dfB[\"PP\"] = dfB[\"P_sys\"] - dfB[\"P_dia\"]\n",
    "#del dfA[\"stroke_work_int\"]\n",
    "#del dfB[\"stroke_work_int\"]\n",
    "for df in dfsC:\n",
    "    df[\"PP\"] = df[\"P_sys\"] - df[\"P_dia\"]\n",
    "    #del df[\"stroke_work_int\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_a = dfA.values\n",
    "y_b = dfB.values\n",
    "y_c = np.array([np.stack(df.values) for df in dfsC])\n",
    "s_i, s_t_i = mc.calculate_sensitivity_indices(y_a, y_b, y_c)\n",
    "\n",
    "df_Sm = pd.DataFrame(index=input_names, columns=dfA.columns, data=s_i)\n",
    "df_St = pd.DataFrame(index=input_names, columns=dfA.columns, data=s_t_i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for ns in [2500, 3500, 4500]:\n",
    "#for ns in [500, 750, 900, 950]:\n",
    "    s_i_check, s_t_i_check = mc.calculate_sensitivity_indices(y_a[0:ns], y_b[0:ns], y_c[:,0:ns])\n",
    "    df_Sm_err = pd.DataFrame(index=input_names, columns=dfA.columns, data=s_i - s_i_check)\n",
    "    df_St_err = pd.DataFrame(index=input_names, columns=dfA.columns, data=s_i - s_t_i_check)\n",
    "    print(\"Samples {} max global error: {}, {}\".format(ns,\n",
    "                                                df_Sm_err.abs().max().max(),\n",
    "                                                df_St_err.abs().max().max()))\n",
    "    print(\"Max error by variable\")\n",
    "    print(\"max S_m error\", df_Sm_err.abs().max())\n",
    "    print(\"max S_t error\", df_St_err.abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## dy/dx *(x/y) * 100 -> percent change in y per 100 percent change in x\n",
    "df_X_pct_change = pd.DataFrame((cp.Std(joint_dist)/cp.E(joint_dist)), index=input_names)\n",
    "display(100 * np.sqrt(np.abs(df_Sm)).div(df_X_pct_change[0], axis=0) * (dfA.std()/dfA.mean()))\n",
    "# percent variation in Y  due to  100% variation in X \n",
    "display(closed_loop_ofat_results[\"pct_sens\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(df_Sm)\n",
    "display(closed_loop_ofat_results[\"sigma_sens\"])\n",
    "display(np.max(df_Sm - closed_loop_ofat_results[\"sigma_sens\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_loop_gsa =  dict(input_names=input_names, df_Sm=df_Sm, df_St=df_St, dfA=dfA)\n",
    "%store closed_loop_gsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Sm = pd.DataFrame(index=input_names, columns=dfA.columns, data=s_i)\n",
    "colors = [\"#feedde\", \n",
    "          \"#fdd0a2\",\n",
    "\"#fdae6b\",\n",
    "\"#fd8d3c\",\n",
    "\"#f16913\",\n",
    "\"#d94801\",\n",
    "\"#8c2d04\"]\n",
    "\n",
    "def highlight_funct(x):\n",
    "    if x > 0.5:\n",
    "        ret_val = 'background-color: %s' % colors[0]\n",
    "    elif x>0.4:\n",
    "        ret_val = 'background-color : %s' % colors[1]\n",
    "    elif x>0.3:\n",
    "        ret_val = 'background-color : %s' % colors[2]\n",
    "    elif x>0.2:\n",
    "        ret_val = 'background-color : %s' % colors[3]\n",
    "    elif x>0.1:\n",
    "        ret_val = 'background-color : %s' % colors[4]\n",
    "    elif x>0.05:\n",
    "        ret_val = 'background-color : %s' % colors[5]\n",
    "    else:    \n",
    "        ret_val =  'background-color: %s' % colors[6]\n",
    "    return ret_val\n",
    "        \n",
    "    \n",
    "df_Sm.style.applymap(highlight_funct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_St = pd.DataFrame(index=input_names, columns=dfA.columns, data=s_t_i)\n",
    "df_St.style.applymap(highlight_funct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(9,9))\n",
    "sns.heatmap(df_Sm, ax=ax[0])# center=0)\n",
    "sns.heatmap(df_St, ax=ax[1])# center=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if Ns == 1000:\n",
    "    var = \"P_ao\"\n",
    "    y_a = np.stack(dfA[var].values)\n",
    "    y_b = np.stack(dfB[var].values)\n",
    "    y_c = np.array([np.stack(df[var].values) for df in dfsC])\n",
    "    s_i, s_t_i = mc.calculate_sensitivity_indices(y_a, y_b, y_c)\n",
    "    #print(s_i)\n",
    "    plt.figure()\n",
    "    for idx, s_t in enumerate(s_t_i):\n",
    "        h = plt.plot(s_t, label=input_names[idx])\n",
    "        plt.plot(s_i[idx], '--', color=h[0].get_color())\n",
    "    plt.legend(loc=\"upper left\", bbox_to_anchor=(1,1))\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Ns == 500:\n",
    "    var = \"P_ao\"\n",
    "    # y_a = np.stack(dfA[var].values).mean(axis=1)\n",
    "    # y_b = np.stack(dfB[var].values).mean(axis=1)\n",
    "    # y_c = np.array([np.stack(df[var].values) for df in dfsC]).mean(axis=1)\n",
    "    y_a = np.stack(dfA[var].values)\n",
    "    y_b = np.stack(dfB[var].values)\n",
    "    y_c = np.array([np.stack(df[var].values) for df in dfsC])\n",
    "    s_i, s_t_i = mc.calculate_sensitivity_indices(y_a, y_b, y_c)\n",
    "    #print(s_i)\n",
    "    plt.figure()\n",
    "    for idx, s_t in enumerate(s_t_i):\n",
    "        h = plt.plot(s_t, label=input_names[idx])\n",
    "        plt.plot(s_i[idx], '--', color=h[0].get_color())\n",
    "    plt.legend(loc=\"upper left\", bbox_to_anchor=(1,1))\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = \"Q_lvao\"\n",
    "y_a = np.stack(dfA[var].values).mean(axis=1)\n",
    "y_b = np.stack(dfB[var].values).mean(axis=1)\n",
    "y_c = np.array([np.stack(df[var].values) for df in dfsC]).mean(axis=2)\n",
    "s_i, s_t_i = mc.calculate_sensitivity_indices(y_a, y_b, y_c)\n",
    "print(input_names)\n",
    "print(s_i)\n",
    "print(s_t_i)\n",
    "plt.figure()\n",
    "plt.plot(s_t_i)\n",
    "plt.gca().set(xticks=np.arange(len(input_names)))\n",
    "plt.gca().set(xticklabels=input_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = \"P_ao\"\n",
    "y_a = np.stack(dfA[var].values).max(axis=1)\n",
    "y_b = np.stack(dfB[var].values).max(axis=1)\n",
    "y_c = np.array([np.stack(df[var].values) for df in dfsC]).max(axis=2)\n",
    "s_i, s_t_i = mc.calculate_sensitivity_indices(y_a, y_b, y_c)\n",
    "print(input_names)\n",
    "print(s_i)\n",
    "print(s_t_i)\n",
    "plt.figure()\n",
    "plt.plot(s_t_i)\n",
    "plt.gca().set(xticks=np.arange(len(input_names)))\n",
    "plt.gca().set(xticklabels=input_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = \"P_ao\"\n",
    "y_a = np.stack(dfA[var].values).min(axis=1)\n",
    "y_b = np.stack(dfB[var].values).min(axis=1)\n",
    "y_c = np.array([np.stack(df[var].values) for df in dfsC]).min(axis=2)\n",
    "s_i, s_t_i = mc.calculate_sensitivity_indices(y_a, y_b, y_c)\n",
    "print(input_names)\n",
    "print(s_i)\n",
    "print(s_t_i)\n",
    "plt.figure()\n",
    "plt.plot(s_t_i)\n",
    "plt.gca().set(xticks=np.arange(len(input_names)))\n",
    "plt.gca().set(xticklabels=input_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
